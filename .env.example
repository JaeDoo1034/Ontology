# Required for OpenAI provider
OPENAI_API_KEY=

# Default provider: openai | local
LLM_PROVIDER=openai

# OpenAI model for cloud mode
OPENAI_MODEL=gpt-4o-mini

# Memori integration toggle (0=off, 1=on)
MEMORI_ENABLED=0

# Local OpenAI-compatible endpoint (e.g. Ollama, vLLM, LM Studio)
LOCAL_BASE_URL=http://localhost:11434/v1
LOCAL_API_KEY=local
LOCAL_MODEL=qwen2.5:3b

# Shared SQLite DB for ontology + memori
SQLITE_PATH=./data/ontology_memori.db
API_HOST=0.0.0.0
API_PORT=8000

# Memori attribution
ENTITY_ID=user-001
PROCESS_ID=ontology-agent

# (Recommended) HF auth for better rate limits / faster model downloads
HF_TOKEN=

# Memori embedding model (default is all-MiniLM-L6-v2)
MEMORI_EMBEDDINGS_MODEL=all-MiniLM-L6-v2

# Prompt budget controls
MAX_ONTOLOGY_FACTS=5
MAX_RELATIONS=3
MAX_CONTEXT_CHARS=1200
PROMPT_BUDGET_MODE=balanced
PROMPT_TOKEN_WARN_THRESHOLD=220

# Logging
LOG_LEVEL=INFO

# Default method in UI/API
ONTOLOGY_METHOD_DEFAULT=method1

# Method1 (Keyword Grounding)
M1_KEYWORD_MIN_TOKEN_LEN=2
M1_KEYWORD_LIMIT=15

# Method2 (Ontology Prompting / Policy)
M2_POLICY_STRICT_MODE=1
M2_POLICY_MAX_RULES=20

# Method3/4 (GraphRAG / KG Reasoning)
GRAPH_BACKEND=sqlite
GRAPH_TOP_K=20
GRAPH_MAX_HOPS=2
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=neo4j
NEO4J_DATABASE=neo4j

# Method5 (Embedding Retrieval)
EMBEDDING_PROVIDER=sentence-transformers
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
VECTOR_DB_PROVIDER=chroma
CHROMA_PERSIST_DIR=./data/chroma
VECTOR_TOP_K=10
HYBRID_ALPHA=0.7

# Method6/7 (Neuro-symbolic / Verification)
RULE_ENGINE=z3
RULE_STRICT_MODE=1
VERIFICATION_CANDIDATES=3
CONFIDENCE_THRESHOLD=0.65

# Method8 (Ontology Enrichment)
ENRICHMENT_MAX_PROPOSALS=5
ENRICHMENT_ALLOW_NEW_RELATIONS=1
ENRICHMENT_AUTO_APPLY=0
ONTOLOGY_EXPORT_PATH=./data/ontologies/generated
